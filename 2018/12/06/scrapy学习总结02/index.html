<!DOCTYPE html>
<html lang=>
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="description" content="">
  <meta name="keywords" content="">
  
    <link rel="icon" href="/favicon.ico">
  
    
  <title>scrapy学习总结02 | tomxxkl的个人博客</title>
  <link rel="stylesheet" href="/style.css">
  <link rel="stylesheet" href="/lib/jquery.fancybox.min.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <header>
  <div class="header-container">
    <a class='logo' href="/">
      <span>tomxxkl的个人博客</span>
    </a>
    <ul class="right-header">
      
        <li class="nav-item">
          
            <a href="/" class="item-link">首页</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/about" class="item-link">关于</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/archives" class="item-link">归档</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/tags" class="item-link">标签</a>
          
        </li>
      
    </ul>
  </div>
</header>

  <main id='post'>
  <div class="content">
    <article>
        <section class="content markdown-body">
          <h1>scrapy学习总结02</h1>
          <div class='post-meta'>
            <i class="fa fa-calendar" aria-hidden="true"></i> <time>2018/12/06</time>
            
            
          </div>
          <h3 id="1-通过scrapy下载图片并保存"><a href="#1-通过scrapy下载图片并保存" class="headerlink" title="1.通过scrapy下载图片并保存"></a>1.通过scrapy下载图片并保存</h3><p>scrapy保存图片，需要在piplines里面创建一个保存图片的pipline类，这个类需要继承ImagesPipeline，这个类有三个方法,分别是get_media_requests()、file_path()和item_completed()。他们分别的作用是</p>
<p>get_media_requests(self, item, info):构造图片的url请求，并yield除相应的请求对象</p>
<p>file_path(self, request, response=None, info=None):根据当前请求的url分析出文件名，并return这个文件名</p>
<p>item_completed(self, results, item, info):通过results判断图片下载是否成功，如果不成功就抛出文件加载异常，如果成功就return已经封装好的item对象</p>
<p>完成上述编写后需要修改settings.py文件里的pipline配置,之后文件就可以自动保存了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'zhancool.pipelines.ZhancoolImagePipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>例子:爬取站酷网图片</p>
<p>piplines.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhancoolImagePipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="comment">#返回图片文件名</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        filename = request.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断图片下载请求是否成功</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">'Image Downloaded Failed'</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造图片url请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> Request(item[<span class="string">'preview_url'</span>])</span><br></pre></td></tr></table></figure>
<p>cool.py:爬取器的py文件，站酷的图片是通过post请求获取的，并且在第二次获取的时候实际连接和发送连接不同</p>
<p>需要加上第一次获取返回的next_page_ulr的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> zhancool.items <span class="keyword">import</span> ZhancoolItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CoolSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'cool'</span></span><br><span class="line">    allowed_domains = [<span class="string">'hellorf.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.hellorf.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'</span>,</span><br><span class="line">            <span class="string">'Accept'</span>: <span class="string">'application/json, text/plain, */*'</span>,</span><br><span class="line">            <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, sdch'</span>,</span><br><span class="line">            <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6,ja;q=0.4,zh-TW;q=0.2,mt;q=0.2'</span>,</span><br><span class="line">            <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">            <span class="string">'X-Requested-With'</span>: <span class="string">'XMLHttpRequest'</span>,</span><br><span class="line">            <span class="string">'Content-Type'</span>: <span class="string">'application/json;charset=utf-8'</span>,</span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'api.hellorf.com'</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">101</span>):</span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">'keyword'</span>: <span class="string">'网站'</span>,</span><br><span class="line">                <span class="string">'page'</span>: str(i),</span><br><span class="line">                <span class="string">'searchod'</span>: <span class="string">'xwIGpLYI8'</span>,</span><br><span class="line">                <span class="string">'sort'</span>: <span class="string">'newest'</span>,</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.FormRequest (url=<span class="string">'https://api.hellorf.com/hellorf/image/search?page='</span>+str(i),</span><br><span class="line">                                headers=headers,</span><br><span class="line">                                method=<span class="string">'POST'</span>,</span><br><span class="line">                                formdata=data,</span><br><span class="line">                                callback=self.parse,</span><br><span class="line">                                )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        json_result = json.loads(response.text)</span><br><span class="line">        data_list = json_result[<span class="string">'data'</span>][<span class="string">'data'</span>]</span><br><span class="line">        <span class="keyword">for</span> img_item <span class="keyword">in</span> data_list:</span><br><span class="line">            item = ZhancoolItem()</span><br><span class="line">            item[<span class="string">'item_id'</span>] = img_item.get(<span class="string">'_id'</span>, <span class="string">''</span>)</span><br><span class="line">            item[<span class="string">'title'</span>] = img_item.get(<span class="string">'title'</span>, <span class="string">''</span>)</span><br><span class="line">            item[<span class="string">'preview_url'</span>] = img_item.get(<span class="string">'preview_url'</span>, <span class="string">''</span>)</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p>item.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhancoolItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    item_id = scrapy.Field()</span><br><span class="line">    preview_url = scrapy.Field()</span><br></pre></td></tr></table></figure>

        </section>
    </article>
    
        <!-- disqus 评论框 start -->
        <div class="comment">
            <div id="disqus_thread" class="disqus-thread">
              <i>Loading comments box needs to over the wall</i>
            </div>
        </div>
        <!-- disqus 评论框 end -->
    
    
        <!-- livere 评论框 start -->
        <div class="comment">
            <div id="lv-container" data-id="city" data-uid="your_livere_uid"></div>
        </div>
        <!-- livere 评论框 end -->
        
  </div>
  <aside>
    
    <div class="toc-container">
        <h1>目录</h1>
        <div class="content">
            <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-通过scrapy下载图片并保存"><span class="toc-number">1.</span> <span class="toc-text">1.通过scrapy下载图片并保存</span></a></li></ol>
        </div>
    </div>
    
  </aside>
</main>

<!-- disqus 公共JS代码 -->
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES * * */
  var disqus_shortname = "your_disqus_shortname";
  var disqus_identifier = "http://yoursite.com/2018/12/06/scrapy学习总结02/";
  var disqus_url = "http://yoursite.com/2018/12/06/scrapy学习总结02/";

  isAgent(getDisqus)

  // determine user agent in China
  function isAgent(cb) {
    var url = '//graph.facebook.com/feed?callback=h';
    var xhr = new XMLHttpRequest();
    var called = false;
    xhr.open('GET', url);
    xhr.onreadystatechange = function() {
      if (xhr.readyState === 4 && xhr.status === 200) {
      called = true;
      cb(true);
      }
    };
    xhr.send();
    // timeout 1s, this facebook API is very fast.
    setTimeout(function() {
      if (!called) {
      xhr.abort();
      cb(false)
      }
    }, 1000);
  }

  function getDisqus(isAgent) {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; 
    dsq.async = true
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq)
  }
</script>
<!-- disqus 公共JS代码 end -->


<script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>


  <footer>
  <div class="copyright">
    <div>
      &copy; 2019 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a>&nbsp
    </div>
    <div>
      Theme by <a href="https://github.com/lewis-geek/hexo-theme-Aath" target="_blank">Aath</a>
    </div>
  </div>
</footer>


<script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="/lib/in-view.min.js"></script>
<script src="/lib/lodash.min.js"></script>
<script>
  var isDown = true
  var oldY = 0
  inView.offset(50)

  document.body.addEventListener('touchstart', function(){});
  
  window.addEventListener('scroll', _.throttle(e => {
    var currentY = window.scrollY
    if((oldY - currentY) < 0) {
      isDown = true
    } else {
      isDown = false
    }
    oldY = currentY
  }, 250))

  $("article img").each(function() {
      var strA = "<a data-fancybox='gallery' href='" + this.src + "'></a>";
      $(this).wrapAll(strA);
  });

  $('.toc-link').each(function() {
      var href = $(this).attr("href");
      
      inView(href).on('exit', () => {
        if (isDown) {
          handleActive(href)
        }
      })

      inView(href).on('enter', () => {
        if (!isDown) {
          handleActive(href)
        }
      })

      this.onclick = function(e) {
        var pos = $(href).offset().top - 10;
        $("html,body").animate({scrollTop: pos}, 300);
        setTimeout(() => {
          handleActive(href)
        }, 350)
        return false
      }
  })

  function handleActive(href) {
    document.querySelectorAll('.toc-link').forEach(elm => {
      elm.classList.remove('active')
    })
    document.querySelector(".toc [href='"+ href +"']").classList.add('active')
  }
</script>
<script src="/lib/jquery.fancybox.min.js"></script>


</body>
</html>
